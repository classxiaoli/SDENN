{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此程序有毒 : 注释掉不用的方法或者属性时,得到的结果不一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kzw\\AppData\\Local\\conda\\conda\\envs\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Python imports\n",
    "import numpy as np # Matrix and vector computation package\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "# Allow matplotlib to plot inside this notebook\n",
    "%matplotlib inline\n",
    "# Set the seed of the numpy random number generator so that the tutorial is reproducable\n",
    "np.random.seed(seed=1)\n",
    "from sklearn import datasets, cross_validation, metrics # data and evaluation utils\n",
    "from matplotlib.colors import colorConverter, ListedColormap # some plotting functions\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "T = np.zeros((digits.target.shape[0],10))\n",
    "T[np.arange(len(T)), digits.target] += 1\n",
    "\n",
    "X_train, X_test, T_train, T_test = cross_validation.train_test_split(\n",
    "    digits.data, T, test_size=0.4)\n",
    "X_validation, X_test, T_validation, T_test = cross_validation.train_test_split(\n",
    "    X_test, T_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzEAAABxCAYAAADlJi1xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAACH1JREFUeJzt3b1SFFsXBuDNV1+OeAMCNyCoOVAFMSaaigmEYgQZkEEGIZGQSiKxVom5lHABx58bELkCzgWcc/baVA8zvajnSVfbs2m7e+atrup37ObmpgAAAGTxv1EvAAAA4DaEGAAAIBUhBgAASEWIAQAAUhFiAACAVIQYAAAgFSEGAABIRYgBAABSEWIAAIBUhBgAACAVIQYAAEhFiAEAAFIRYgAAgFSEGAAAIBUhBgAASEWIAQAAUhFiAACAVIQYAAAgFSEGAABIRYgBAABSEWIAAIBUhBgAACAVIQYAAEhFiAEAAFIRYgAAgFSEGAAAIBUhBgAASEWIAQAAUhFiAACAVIQYAAAgFSEGAABIRYgBAABS+f+IPvemyz8+OTkJt9nY2KjOl5aWqvPd3d3qfGJiIlxDg7Fbbt/puLWYn5+vzv/8+VOd7+zsVOfLy8u3XdK/ue1xK2UIx+7s7Kw6f/78eXU+MzPTaf+Nhn7s9vb2wm02Nzer86mpqer8/Py8Oh/R9VrKEM676JpcWVmpzj98+DDA1fynoR+76F5WSimTk5PV+dHRUZclDMq9+564uLgY4Gr+09DPuf39/XCb6NhE1+Pl5WV1Pj4+Hq7h58+f1fmDBw+GfuzW19fDbaJjE93ros948OBBuIYGQz920W+LUuLzbkC/L7q69bHzJAYAAEhFiAEAAFIRYgAAgFSEGAAAIBUhBgAASEWIAQAAUhFiAACAVEbVE9NJ1AFTSik/fvyozq+urqrzhw8fVufv378P1/DixYtwm76J3pP+5cuX6vzz58/V+YB6YoaupddgYWGhOo/e3x+9u7+voo6Xlmvl8PCwOl9bW6vOo56YxcXFcA1ZRV0mUf/QfdVyPUX3s+Pj4+r80aNHndfQN6enp+E20XHb2toa1HLuneg7NuqaieZRH0jLGkZhEN1B0b0w6kLpSVfKP0T3kZZrNjI2Vq9oefz4cXU+pO6nf/AkBgAASEWIAQAAUhFiAACAVIQYAAAgFSEGAABIRYgBAABSEWIAAIBUetkTE3U+RB0wpZTy119/VefT09PV+dLSUnUerbGU/vXEtLzHu+t70u9rJ8WHDx/CbaL3qD9//rw639nZudWa+mJ1dbU6b+l1evr0aXU+NTVVnd/XHpiWzoeoG2F9fb06H0SXyeTkZOd9DFpLF8avX7+q86jbaX5+vjrP2NkxiI6X6F53X0XXWovt7e3qPLpe+9p1Emn57RDdZ6J7YXSttRy76Jq/Cy33kcjc3Fx1Hh3bvp5XnsQAAACpCDEAAEAqQgwAAJCKEAMAAKQixAAAAKkIMQAAQCpCDAAAkIoQAwAApNLLssurq6vq/MmTJ+E+ojLLSFS+10f7+/vVeVSiVUop19fXndYwiiKoYWgpMYvKoqJ9LC8v32ZJvRFda9+/fw/3ERXYRmWW0T1jYmIiXEMfReVtpcTldysrK9V5dF62lDG23FuGraWA8/LysjqP7odRQV/fiixbtBTrRcW+97X0OCr8G0QhYPQ9HmkpZo7uCaPQsqbZ2dnqPLoXRtdjH0t7SxnMuqLzIiqoHUTh5l3wJAYAAEhFiAEAAFIRYgAAgFSEGAAAIBUhBgAASEWIAQAAUhFiAACAVFL2xCwtLY18DX3snYj6Hlrew9717+rru8Qj0bpb3t3f8n7+mpZOkIxaOpt+//5dnUc9MdH806dP4RpGcU2fnp5W52/fvg338erVq05rODg4qM7fvXvXaf+j0nI9Rr0eFxcX1XnL/0+kpYNqmFru4VFvRXS/jDopsvZ1ROdLKd27ZKLzOmtX2yB+O3z58qU6j/rI+nreRf02UW9TKfH325s3b6rz6NyOOnpKuZvj60kMAACQihADAACkIsQAAACpCDEAAEAqQgwAAJCKEAMAAKQixAAAAKn0sicmep/1+fl558+IemC+fv1anb98+bLzGu6j6F3iMzMzQ1rJ7Wxvb1fnUZdGi+j9/tG74O+z6JqPel7W1taq8729vXANu7u74TaDNj4+3mleSinHx8fVeUt3RU3U6ZHZXXdqtHQn9E1Ll0PUxxF1fkT9Ot++fQvXMIrvkujYtHQTjY2NddpH1h6Y6D60sLAQ7mNra6s6j6636F7W8v/Xxy6Zlnv8Xf82a+m76tql9288iQEAAFIRYgAAgFSEGAAAIBUhBgAASEWIAQAAUhFiAACAVIQYAAAglV72xExPT1fnUYdLKaWcnJx0mkc2NjY6/Xv6ZWVlpTo/OzsL93F5eVmdR++oX15ers5fv34driHaxyhsbm6G2ywuLlbnUa/Tx48fq/O+9jpFnQ9R30Yp8fv/o8949epVdZ61v+j09DTcJurhifqjIhk7dqJ7YSlxz0vUpRH1ebT0SfSxc6ylKyM65+bm5ga1nF6JzomWTqzo+Ebn1ezsbHV+dHQUrqHrPWFUouslOrbRsbmLDpgWnsQAAACpCDEAAEAqQgwAAJCKEAMAAKQixAAAAKkIMQAAQCpCDAAAkIoQAwAApJKy7HJvby/cR1RG+ezZs+r8/Pw8/IxsWkrrorLEqEAuKoVsKVIbhagIKioUbNkmKsmKjm1UFlZKP8suJyYmwm1WV1c7fUZUZnl4eNhp/30WXdfX19fVeV+vya4+f/4cbnNwcNDpM6Ki0KhotI9azoeoVDAqxouOS8aS0FLaSpGPj4+r86zlspHo72q5VqLvkqgwM/p+bCkr7aOWdUe/T6Ji5ejcHlX5rCcxAABAKkIMAACQihADAACkIsQAAACpCDEAAEAqQgwAAJCKEAMAAKQydnNzM+o1AAAANPMkBgAASEWIAQAAUhFiAACAVIQYAAAgFSEGAABIRYgBAABSEWIAAIBUhBgAACAVIQYAAEhFiAEAAFIRYgAAgFSEGAAAIBUhBgAASOVvx6glF3V17qkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x100 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 1), dpi=100)\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(1,10,i+1)\n",
    "    ax.matshow(digits.images[i], cmap='binary') \n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the non-linear functions used\n",
    "def logistic(z): \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_deriv(y):  # Derivative of logistic function\n",
    "    return np.multiply(y, (1 - y))\n",
    "    \n",
    "def softmax(z): \n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers used in this model\n",
    "class Layer(object):\n",
    "    \n",
    "#     def get_params_iter(self):\n",
    "#         \"\"\"Return an iterator over the parameters (if any).\n",
    "#         The iterator has the same order as get_params_grad.\n",
    "#         The elements returned by the iterator are editable in-place.\"\"\"\n",
    "#         return []\n",
    "    \n",
    "    def get_params_grad(self, X, output_grad):\n",
    "        return [],[]\n",
    "    \n",
    "    # def add高斯noise *****\n",
    "#     def add_gaosi_noise(self):\n",
    "#         pass\n",
    "    \n",
    "    # def remove高斯noise *****\n",
    "#     def remove_gaosi_noise(self):\n",
    "#         pass\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        pass\n",
    "    \n",
    "    def get_input_grad(self, Y, output_grad=None, T=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(Layer):\n",
    "    \n",
    "    def __init__(self, n_in, n_out,sigm):\n",
    "        self.W = np.random.randn(n_in, n_out) * 0.1\n",
    "        self.b = np.zeros(n_out)\n",
    "        self.sig = sigm\n",
    "        # 存下本层的结点数*****\n",
    "        self.nodenum = n_out\n",
    "        self.gaosi_noise = 0\n",
    "        self.curbs = 0\n",
    "        \n",
    "    # def add高斯noise *****\n",
    "#     def add_gaosi_noise(self):\n",
    "#         self.gaosi_noise = np.random.randn(self.curbs, self.nodenum) * self.sig\n",
    "        \n",
    "#     # def remove高斯noise *****\n",
    "#     def remove_gaosi_noise(self):\n",
    "#         self.gaosi_noise = 0\n",
    "        \n",
    "#     def get_params_iter(self):\n",
    "#         \"\"\"Return an iterator over the parameters.\"\"\"\n",
    "#         return itertools.chain(np.nditer(self.W, op_flags=['readwrite']),\n",
    "#                                np.nditer(self.b, op_flags=['readwrite']))\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        return X.dot(self.W) + self.gaosi_noise + self.b\n",
    "        \n",
    "    def get_params_grad(self, X, output_grad):\n",
    "        JW = X.T.dot(output_grad)\n",
    "        Jb = np.sum(output_grad, axis=0)\n",
    "        return [g for g in itertools.chain(np.nditer(JW), np.nditer(Jb))],JW\n",
    "    \n",
    "    def get_input_grad(self, Y, output_grad):\n",
    "        return output_grad.dot(self.W.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticLayer(Layer):\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        return logistic(X)\n",
    "    \n",
    "    def get_input_grad(self, Y, output_grad):\n",
    "        return np.multiply(logistic_deriv(Y), output_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxOutputLayer(Layer):\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        return softmax(X)\n",
    "    \n",
    "    def get_input_grad(self, Y, T):\n",
    "        re = (Y - T) / 1                      #Y.shape[0]   # 大更改 : batchsize大于1时除以样本数,此例子batchsize为1应除以1\n",
    "#         print(\"--------- input_grad ----------\")\n",
    "#         print(\"T.shape : \" + str(T.shape))\n",
    "#         print(\"Y.shape : \" + str(Y.shape))\n",
    "#         print(\"Y.shape[0] : \" + str(Y.shape[0]))\n",
    "#         print(\"Y - T : \" + str((Y - T).shape))\n",
    "        \n",
    "        return re\n",
    "    \n",
    "    def get_cost(self, Y, T):\n",
    "        \n",
    "#         print(\"--------- cost ----------\")\n",
    "#         print(\"T.shape : \" + str(T.shape))\n",
    "#         print(\"Y.shape : \" + str(Y.shape))\n",
    "#         print(\"Y.shape[0] : \" + str(Y.shape[0]))\n",
    "#         print(\"Y - T : \" + str((Y - T).shape))\n",
    "        \n",
    "        return - np.multiply(T, np.log(Y)).sum() / 1      #Y.shape[0]                                 大更改: 单样本时应该除以1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20L,)\n",
      "(10L,)\n"
     ]
    }
   ],
   "source": [
    "# Define a sample model to be trained on the data\n",
    "sigm = 0.5\n",
    "hidden_neurons_1 = 20  # Number of neurons in the first hidden-layer\n",
    "hidden_neurons_2 = 20  # Number of neurons in the second hidden-layer\n",
    "# Create the model\n",
    "layers = [] # Define a list of layers\n",
    "# Add first hidden layer\n",
    "layers.append(LinearLayer(X_train.shape[1], hidden_neurons_1,sigm))\n",
    "layers.append(LogisticLayer())\n",
    "# Add second hidden layer\n",
    "# layers.append(LinearLayer(hidden_neurons_1, hidden_neurons_2))\n",
    "# layers.append(LogisticLayer())\n",
    "# Add output layer\n",
    "layers.append(LinearLayer(hidden_neurons_2, T_train.shape[1],sigm))\n",
    "layers.append(SoftmaxOutputLayer())\n",
    "\n",
    "print(layers[0].b.shape)\n",
    "print(layers[2].b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_step(input_samples,layers,bs,noise1):\n",
    "    activations = [input_samples]\n",
    "    X = input_samples\n",
    "    for index in range(len(layers)):\n",
    "        layer = layers[index]\n",
    "        layer.curbs = bs\n",
    "        #layer.add_gaosi_noise()\n",
    "        layer.gaosi_noise = noise1[index]\n",
    "        Y = layer.get_output(X) \n",
    "        activations.append(Y) \n",
    "        X = activations[-1]  \n",
    "    return activations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 前向传播 : add 高斯nosie *****\n",
    "# def forward_step2(input_samples, layers):\n",
    "#     activations = [input_samples] # List of layer activations\n",
    "#     X = input_samples\n",
    "#     for layer in layers:\n",
    "#         # *****remove\n",
    "#         layer.remove_gaosi_noise()\n",
    "#         Y = layer.get_output(X) \n",
    "#         activations.append(Y) \n",
    "#         X = activations[-1]  \n",
    "#     return activations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the backward propagation step as a method\n",
    "def backward_step(activations, targets, layers):\n",
    "    param_grads = collections.deque() \n",
    "    jws = collections.deque() #***** get每一层的JW\n",
    "    output_grad = None \n",
    "    for layer in reversed(layers):   \n",
    "        Y = activations.pop() \n",
    "        if output_grad is None:\n",
    "            input_grad = layer.get_input_grad(Y, targets)\n",
    "        else: \n",
    "            input_grad = layer.get_input_grad(Y, output_grad) # 输出a + 输出导数 -> 得输入导数  linear层时Y没有用到\n",
    "        X = activations[-1]\n",
    "        grads,JW = layer.get_params_grad(X, output_grad)      # 输入a + 输出导数 -> 此层的grad\n",
    "        \n",
    "#         print(\"--------------- JW ---------------\")\n",
    "#         print(len(JW))\n",
    "#         print(\"JW.shape : \" + str(JW.shape))\n",
    "#         print(\"JW.type : \" + str(type(JW)))\n",
    "        \n",
    "        param_grads.appendleft(grads)\n",
    "        output_grad = input_grad\n",
    "        jws.appendleft(JW) #get本层的JW\n",
    "    return list(param_grads),jws "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the minibatches\n",
    "# batch_size = 25  # Approximately 25 samples per batch\n",
    "# nb_of_batches = X_train.shape[0] / batch_size  # Number of batches\n",
    "# # Create batches (X,Y) from the training set\n",
    "# XT_batches = zip(\n",
    "#     np.array_split(X_train, nb_of_batches, axis=0),  # X samples\n",
    "#     np.array_split(T_train, nb_of_batches, axis=0))  # Y targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a method to update the parameters\n",
    "# def update_params(layers, param_grads, learning_rate):\n",
    "#     \"\"\"\n",
    "#     Function to update the parameters of the given layers with the given gradients\n",
    "#     by gradient descent with the given learning rate.\n",
    "#     \"\"\"\n",
    "#     for layer, layer_backprop_grads in zip(layers, param_grads):\n",
    "#         for param, grad in itertools.izip(layer.get_params_iter(), layer_backprop_grads):\n",
    "#             # The parameter returned by the iterator point to the memory space of\n",
    "#             #  the original layer and can thus be modified inplace.\n",
    "#             param -= learning_rate * grad  # Update each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "均值    : 4.689701585513435e-05\n",
      "标准误差 : 0.000000157598302\n"
     ]
    }
   ],
   "source": [
    "# Perform backpropagation\n",
    "# initalize some lists to store the cost for future analysis        \n",
    "minibatch_costs = []\n",
    "training_costs = []\n",
    "validation_costs = []\n",
    "\n",
    "#取单张图片\n",
    "x1 = digits.data[0]\n",
    "x1 = np.expand_dims(x1, axis=0)\n",
    "t1 = T[0]\n",
    "# x1 = X_train[0]\n",
    "# x1 = np.expand_dims(x1, axis=0)\n",
    "# t1 = T_train[0]\n",
    "# print(x1.shape)\n",
    "# print(type(x1))\n",
    "# print(x1)\n",
    "# print(\"---------------------------------------------------------------\")\n",
    "# print(t1.shape)\n",
    "# print(type(t1))\n",
    "# print(t1)\n",
    "\n",
    "max_nb_of_iterations = 50000\n",
    "# 存下每次迭代时此节点第一个权重的grad\n",
    "w = []\n",
    "layer_index,node_index,weight_index = 3,5,6 #layer : 1,3\n",
    "for iteration in range(max_nb_of_iterations):\n",
    "    \n",
    "    # 准备好各layer的高斯noise\n",
    "    noise1 = []\n",
    "    noise1.append(np.random.randn(1,20)*sigm)\n",
    "    noise1.append([])\n",
    "    noise1.append(np.random.randn(1,10)*sigm)\n",
    "    noise1.append([])\n",
    "    \n",
    "    bs = 1\n",
    "    activations = forward_step(x1,layers,bs,noise1)\n",
    "    #get所有层w的梯度\n",
    "    param_grads,jws = backward_step(activations, t1, layers)  \n",
    "    #update_params(layers, param_grads, learning_rate)  \n",
    "    w.append(jws[layer_index - 1][weight_index - 1][node_index - 1]) # jws[0]:(64,20)  jws[1]:[]  jws[2]:(20L, 10L)  jws[3]:[]   \n",
    "    \n",
    "    # 显示迭代次数\n",
    "    if (iteration + 1) % 10000 == 0:\n",
    "        print(iteration + 1) \n",
    "#     print(jws[0].shape)\n",
    "#     print(jws[2].shape)\n",
    "#     print(\"=========================== 一个循环 ==========================\")\n",
    "# 显示w的方差和均值\n",
    "print('均值    : '+ str(np.mean(w)))\n",
    "print('标准误差 : '+ \"{:.15f}\".format( np.std(w)/np.math.sqrt(max_nb_of_iterations) ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均值 :    -0.03443065851885252 4607\n",
    "# 标准误差 : 0.000170076698902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 64L)\n",
      "<type 'numpy.ndarray'>\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      "  15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "   0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "   0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "---------------------------------------------------------------\n",
      "(10L,)\n",
      "<type 'numpy.ndarray'>\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "print(type(x1))\n",
    "print(x1)\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(t1.shape)\n",
    "print(type(t1))\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLP_gaosi_single_layer_grad_check\n",
    "# (1L, 64L)\n",
    "# <type 'numpy.ndarray'>\n",
    "# [[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
    "#   15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
    "#    0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
    "#    0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]]\n",
    "# ---------------------------------------------------------------\n",
    "# (10L,)\n",
    "# <type 'numpy.ndarray'>\n",
    "# [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLP_weibull_noise_single_layer\n",
    "# (1L, 65L)\n",
    "# <type 'numpy.ndarray'>\n",
    "# [[ 1.  0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.\n",
    "#    3. 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.\n",
    "#    0.  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10.\n",
    "#   12.  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]]\n",
    "# ---------------------------------------------------------------\n",
    "# (10L,)\n",
    "# <type 'numpy.ndarray'>\n",
    "# [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "----------\n",
    "this grad : \n",
    "sigma = 1   index: 3,1,1   全在置信区间\n",
    "0.010026768487083235  0.00991859750727568    0.009983325531141016    0.01011431937186198   0.009947821015864488    0.009963580580966535\n",
    "0.000073841998315     0.000070439199795      0.000072341219021       0.000072881065431     0.000071686513809       0.000070908133642 \n",
    "\n",
    "weibull grad check :       基本都在置信区间\n",
    "0.038497284454554276  0.03832831332933766   0.03854298042073743      0.03802116095823529   0.03866216877078364     0.038755933645660316\n",
    "0.000212768845483     0.000212455621445     0.000212506750095        0.000212098351969     0.000212805240735       0.000212942963834\n",
    "----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证置信区间\n",
    "d1 = 0.00991859750727568\n",
    "eps1 = 0.000070439199795 \n",
    "d2 = 0.01011431937186198\n",
    "eps2 = 0.000072881065431\n",
    "print(d1 + eps1) #大\n",
    "print(d2 - eps2) #小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = X_train[0]\n",
    "# x1 = np.expand_dims(x1, axis=0)\n",
    "# t1 = T_train[0]\n",
    "# print(x1)\n",
    "# print(t1)\n",
    "# [ 1.  0.  2. 13. 16.  4.  0.  0.  0.  0. 12. 12. 12. 15.  0.  0.  0.  0.\n",
    "#   5.  2.  7. 14.  0.  0.  0.  0.  0.  3. 15. 15.  7.  0.  0.  0.  0.  4.\n",
    "#  12. 12. 16.  3.  0.  0.  0.  0.  0.  0. 15.  7.  0.  0.  3. 16.  8.  9.\n",
    "#  16.  6.  0.  0.  1. 11. 12. 14.  9.  0.  0.]\n",
    "# [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the minibatch, full training set, and validation costs\n",
    "minibatch_x_inds = np.linspace(0, nb_of_iterations, num=nb_of_iterations*nb_of_batches)\n",
    "iteration_x_inds = np.linspace(1, nb_of_iterations, num=nb_of_iterations)\n",
    "# Plot the cost over the iterations\n",
    "plt.plot(minibatch_x_inds, minibatch_costs, 'k-', linewidth=0.5, label='cost minibatches')\n",
    "plt.plot(iteration_x_inds, training_costs, 'r-', linewidth=2, label='cost full training set')\n",
    "plt.plot(iteration_x_inds, validation_costs, 'b-', linewidth=3, label='cost validation set')\n",
    "# Add labels to the plot\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('$\\\\xi$', fontsize=15)\n",
    "plt.title('Decrease of cost over backprop iteration')\n",
    "plt.legend()\n",
    "x1,x2,y1,y2 = plt.axis()\n",
    "plt.axis((0,nb_of_iterations,0,2.5))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results of test data\n",
    "y_true = np.argmax(T_test, axis=1)  # Get the target outputs\n",
    "activations = forward_step(X_test, layers)  # Get activation of test samples\n",
    "y_pred = np.argmax(activations[-1], axis=1)  # Get the predictions made by the network\n",
    "test_accuracy = metrics.accuracy_score(y_true, y_pred)  # Test set accuracy\n",
    "print('The accuracy on the test set is {:.2f}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75c37aae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show confusion table\n",
    "conf_matrix = metrics.confusion_matrix(y_true, y_pred, labels=None)  # Get confustion matrix\n",
    "# Plot the confusion table\n",
    "class_names = ['${:d}$'.format(x) for x in range(0, 10)]  # Digit class names\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# Show class labels on each axis\n",
    "ax.xaxis.tick_top()\n",
    "major_ticks = range(0,10)\n",
    "minor_ticks = [x + 0.5 for x in range(0, 10)]\n",
    "ax.xaxis.set_ticks(major_ticks, minor=False)\n",
    "ax.yaxis.set_ticks(major_ticks, minor=False)\n",
    "ax.xaxis.set_ticks(minor_ticks, minor=True)\n",
    "ax.yaxis.set_ticks(minor_ticks, minor=True)\n",
    "ax.xaxis.set_ticklabels(class_names, minor=False, fontsize=15)\n",
    "ax.yaxis.set_ticklabels(class_names, minor=False, fontsize=15)\n",
    "# Set plot labels\n",
    "ax.yaxis.set_label_position(\"right\")\n",
    "ax.set_xlabel('Predicted label')\n",
    "ax.set_ylabel('True label')\n",
    "fig.suptitle('Confusion table', y=1.03, fontsize=15)\n",
    "# Show a grid to seperate digits\n",
    "ax.grid(b=True, which=u'minor')\n",
    "# Color each grid cell according to the number classes predicted\n",
    "ax.imshow(conf_matrix, interpolation='nearest', cmap='binary')\n",
    "# Show the number of samples in each cell\n",
    "for x in xrange(conf_matrix.shape[0]):\n",
    "    for y in xrange(conf_matrix.shape[1]):\n",
    "        color = 'w' if x == y else 'k'\n",
    "        ax.text(x, y, conf_matrix[y,x], ha=\"center\", va=\"center\", color=color)       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
