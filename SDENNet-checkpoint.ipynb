{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 介绍 : 新算法,不加weibull_noise,所有节点加高斯noise,单个样本循环\n",
    "    #grad计算方法 : grad = ( a*noise*loss )/sigm**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kzw\\AppData\\Local\\conda\\conda\\envs\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Python imports\n",
    "import numpy as np # Matrix and vector computation package\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "# Allow matplotlib to plot inside this notebook\n",
    "%matplotlib inline\n",
    "# Set the seed of the numpy random number generator so that the tutorial is reproducable\n",
    "np.random.seed(seed=1)\n",
    "from sklearn import datasets, cross_validation, metrics # data and evaluation utils \n",
    "from matplotlib.colors import colorConverter, ListedColormap # some plotting functions\n",
    "import itertools\n",
    "import collections\n",
    "from scipy import stats\n",
    "from scipy.stats import weibull_min\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#给逻辑层的输出的头部插入1\n",
    "def array_add_data(activ):\n",
    "    \"\"\"\n",
    "    参数activ : 每层的输出(激活)  第一层 : (32L, 20L)\n",
    "    作用 : 在数组头部插入数值1\n",
    "    \"\"\"\n",
    "    r = []\n",
    "    ret1 = 0\n",
    "    for i in range(activ.shape[0]):\n",
    "        ret1 = np.array(np.append([1],activ[i])) #list\n",
    "        r.append(ret1)\n",
    "    r = np.array(r) # 类型转换:list -> array\n",
    "    return r\n",
    "\n",
    "#给所有样本头部插入1\n",
    "def array_add_data2(activ):\n",
    "    \"\"\"\n",
    "        参数activ : 样本\n",
    "        作用 : 在数组头部插入数值1\n",
    "    \"\"\"\n",
    "    r = []\n",
    "    ret1 = np.append([1],activ)\n",
    "    r.append(ret1)\n",
    "    ret2 = np.array(r)\n",
    "    return ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the non-linear functions used\n",
    "def logistic(z): \n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# def logistic_deriv(y):  # Derivative of logistic function\n",
    "#     return np.multiply(y, (1 - y))\n",
    "    \n",
    "def softmax(z): \n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers used in this model\n",
    "class Layer(object):\n",
    "    \n",
    "#     def get_params_iter(self):\n",
    "#         return []\n",
    "    \n",
    "#     def get_params_grad(self, X, output_grad):\n",
    "#         return []\n",
    "      \n",
    "#     def get_params_update(self, X, loss):\n",
    "#         return []\n",
    "    \n",
    "#     def add_noise(self):\n",
    "#         pass\n",
    "    \n",
    "#     def remove_noise(self):\n",
    "#         pass\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        pass\n",
    "    \n",
    "#     def get_input_grad(self, Y, output_grad=None, T=None):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discreteLayer(Layer):\n",
    "    \"\"\"The linear layer performs a linear transformation to its input.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_in, n_out):\n",
    "        \"\"\" \n",
    "            对隐藏层参数进行初始化\n",
    "            n_in是输入变量的数量\n",
    "            n_out是输出变量的数量\n",
    "        \"\"\"\n",
    "        self.W = np.random.randn(n_in, n_out) * 0.1\n",
    "        self.W[0:1,:] = 0 \n",
    "    def get_output(self, X):\n",
    "        # 线性变换\n",
    "        xw = X.dot(self.W)\n",
    "        re = xw + self.noise \n",
    "        return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticLayer(Layer):\n",
    "    \"\"\"The logistic layer applies the logistic function to its inputs.\"\"\"\n",
    "    \n",
    "    def get_output(self, X):\n",
    "        # 在头部插入数值1\n",
    "        logi = logistic(X)\n",
    "        Y = array_add_data(logi)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxOutputLayer(Layer):\n",
    "    \"\"\" \n",
    "        输出层\n",
    "    \"\"\"  \n",
    "    def get_output(self, X):\n",
    "        r = softmax(X)\n",
    "        return r\n",
    "    \n",
    "    def get_cost(self, A, T):\n",
    "        re = - np.multiply(T, np.log(A)).sum() / A.shape[0]      \n",
    "        return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_step(input_samples,layers,noise1):\n",
    "    activations = [input_samples] \n",
    "    X = input_samples\n",
    "    for index in range(len(layers)): \n",
    "        layer = layers[index]\n",
    "        layer.noise = noise1[index]\n",
    "        Y = layer.get_output(X)\n",
    "        activations.append(Y)  \n",
    "        X = activations[-1]  \n",
    "    return activations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到样本\n",
    "\n",
    "# 在所有样本的头部添加数值1\n",
    "digits = datasets.load_digits()\n",
    "d = digits.data # array\n",
    "# print(data.shape) # (1797L, 64L)\n",
    "target_list = [] # list\n",
    "target_data = []\n",
    "# single_array = np.array([1])\n",
    "for i in range(len(d)):\n",
    "    # 取出数据\n",
    "    a = d[i]\n",
    "    # 头部添加1 \n",
    "    a_temp = array_add_data2(a)[0]\n",
    "    # 添加到总的array中\n",
    "    target_list.append(a_temp)\n",
    "target_data = np.array(target_list) \n",
    "\n",
    "T = np.zeros((digits.target.shape[0],10))\n",
    "T[np.arange(len(T)), digits.target] += 1\n",
    "\n",
    "#有问题 : 这里的划分应该是随机的,和digits.data不对应\n",
    "X_train, X_test, T_train, T_test = cross_validation.train_test_split(\n",
    "    target_data, T, test_size=0.4)\n",
    "X_validation, X_test, T_validation, T_test = cross_validation.train_test_split(\n",
    "    X_test, T_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建minibatches\n",
    "# X_train = X_train[0:1024,:] #取1024方便计算\n",
    "# T_train = T_train[0:1024,:]\n",
    "batch_size = 1#    adjust\n",
    "# nb_of_batches = X_train.shape[0] / batch_size  # 32批\n",
    "# # Create batches (X,Y) from the training set\n",
    "# XT_batches = zip(\n",
    "#     np.array_split(X_train, nb_of_batches, axis=0),  \n",
    "#     np.array_split(T_train, nb_of_batches, axis=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得grad\n",
    "def get_grad(ac,noise,sigm,loss):\n",
    "    grad = []\n",
    "    gra = 0\n",
    "    for i in range(len(noise)):\n",
    "        if i%2 == 0 :\n",
    "            a = ac[i]\n",
    "            noi = noise[i]\n",
    "            do  = a.T.dot(noi)\n",
    "            gra = ( do * loss ) / (sigm**2)  \n",
    "            grad.append(gra)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65L, 20L)\n",
      "(21L, 10L)\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "hidden_neurons_1 = 20  # 第一个隐藏层的神经元数目\n",
    "layers = [] #\n",
    "# 添加第一个隐层\n",
    "layers.append(discreteLayer(X_train.shape[1], hidden_neurons_1))  \n",
    "layers.append(LogisticLayer())\n",
    "# 添加输出层\n",
    "layers.append(discreteLayer(21, T_train.shape[1])) \n",
    "layers.append(SoftmaxOutputLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "均值    : -0.8192050492058489\n",
      "标准误差 : 0.009184831349266\n"
     ]
    }
   ],
   "source": [
    "#迭代训练 : 单张图片  指定结点 target_data[0]\n",
    "x1 = target_data[0]\n",
    "t1 = T[0]\n",
    "x1 = np.expand_dims(x1, axis=0)\n",
    "t1 = np.expand_dims(t1, axis=0)\n",
    "\n",
    "# 开始训练\n",
    "sigm = 5  #35\n",
    "max_nb_of_iterations = 50000 # 训练次数\n",
    "# 选定一个结点\n",
    "layer_index,node_index,weight_index = 2,1,1  #layer : 1,2\n",
    "w = []\n",
    "for iteration in range(max_nb_of_iterations): \n",
    "    # 准备好各layer的高斯noise\n",
    "    noise1 = []\n",
    "    noise1.append(np.random.randn(1,20)*sigm)\n",
    "    noise1.append([])\n",
    "    noise1.append(np.random.randn(1,10)*sigm)\n",
    "    noise1.append([])\n",
    "\n",
    "    activations = forward_step(x1,layers,noise1)\n",
    "    loss = layers[-1].get_cost(activations[-1],t1) \n",
    "    grad = get_grad(activations,noise1,sigm,loss) \n",
    "    w_grad = grad[layer_index - 1][weight_index][node_index - 1]\n",
    "    w.append(w_grad)\n",
    "    # 显示循环次数\n",
    "    if (iteration + 1) % 10000 == 0:\n",
    "        print(iteration + 1)\n",
    "#     print(\"========================= 一个循环 =========================\")\n",
    "print('均值    : '+ str(np.mean(w)))\n",
    "print('标准误差 : '+ \"{:.15f}\".format( np.std(w)/math.sqrt(max_nb_of_iterations) )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.793568023579\n",
      "-0.741285767463\n"
     ]
    }
   ],
   "source": [
    "# 验证置信区间\n",
    "d1 = -0.8118846854684239\n",
    "eps1 =  0.009158330944701 *2\n",
    "d2 =  -0.7381045555059148\n",
    "eps2 =   0.001590605978503 *2\n",
    "print(d1 + eps1) #大\n",
    "print(d2 - eps2) #小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层随机选四个权重 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "新算法(仅高斯noise)     :    layer_index,node_index,weight_index = 1,7,20     \n",
    "-0.02299495781291697  -0.03208230897517716  0.029691683647328142  0.0005051942812933979  0.015683560345395267   0.010667274704363511\n",
    " 0.027940004929023     0.027883102498920    0.028175666572146     0.027829473381536      0.027907972439502      0.027906467067519\n",
    " \n",
    "BP(梯度的数值逼近计算grad) : layer_index,node_index,weight_index = 1,7,20     \n",
    "-0.00013162379408626634 -0.0001316227789260882 -0.00013192415576623873 -0.0001304924823058995 -0.00013046200300625976  -0.00013153744794769384\n",
    " 0.000000836652731       0.000000810907371      0.000000801110100       0.000000784006068      0.000000810112149        0.000000812706314\n",
    "    \n",
    "两算法互比结果 : 都互在置信区间内"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
